{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALGORITMA MACHINE LEARNING : USECASE 2 - FRAUD DETECTION <a class='tocSkip'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Problem yang ada yaitu banyak terdapat perubahan pola-pola fraud SLI (panggilan internasional) baru, sehingga semakin banyak pola fraud yang tidak lagi bisa dideteksi dengan menggunakan **rule base**. Dengan memanfaatkan capability AI/ML, maka diharapkan bisa meningkatkan (enhance) **FRAMES**. \n",
    "![ ](assets/Machine-Learning-Task.png)\n",
    "Dengan memanfaatkan salah satu dari 3 (tiga) kategori **Machine Learning** yaitu **Unsupervised Learning** untuk mendeteksi fraud. Hal ini dilakukan karena data yang digunakan tidak memiliki variabel target, sehingga kita akan membiarkan mesin yang mempelajari data tersebut. Selain itu tujuan dari analisa ini yaitu bisa menampilkan informasi tersembunyi dari data yang dapat berguna untuk mendeteksi anomali data. Model yang digunakan yaitu **Anomaly Detection**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "\n",
    "Seperti biasa, sebelum memulai analisa dan modeling, lakukan import beberapa library terkait yang dibutuhkan untuk dikerjakan pada data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda3\\envs\\caps\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Program Files\\Anaconda3\\envs\\caps\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "D:\\Program Files\\Anaconda3\\envs\\caps\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Data Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "from pylab import rcParams\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# Info cell\n",
    "import time\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Modeling\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Magic function\n",
    "%load_ext autoreload\n",
    "%load_ext autotime\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load and Understanding\n",
    "\n",
    "Dataset yang digunakan untuk analisa ada 2 (dua) dengan rentang waktu pengambilan data transaksi selama 1 (satu) bulan, pada bulan maret. Dataset yang dimaksud disimpan ke dalam file, dengan keterangan sebagai berikut : \n",
    "- **fraud_pstn_202003.csv** :  Data kotor transaksi telepon SLI selama 1 (satu) bulan pada bulan maret 2020.\n",
    "- **fraud_pst_maret2020_label1.xlsx** : Data fraud transaksi telepon SLI selama bulan maret dengan rule base.\n",
    "\n",
    "Dataset memiliki nama kolom dengan deskripsi sebagai berikut :\n",
    "- `start` : Tanggal dan jam panggilan telepon dimulai\n",
    "- `end` : Tanggal dan jam panggilan telepon selesai\n",
    "- `source_num` : Nomor telepon asal\n",
    "- `dest_num` : Nomor telepon tujuan\n",
    "- `access_code` : Kode akses yang digunakan untuk panggilan SLI\n",
    "- `org_dest_num` : Kode kelompok nomor telepon tujuan\n",
    "- `duration` : Lama panggilan telepon dalam detik\n",
    "- `dest_country` : Nama negara tujuan telepon\n",
    "- `dest_country_status` : Status kategori dari negara tujuan telepon (COMMON, BLACKLIST, dan WHITELIST)\n",
    "\n",
    "\n",
    "\n",
    "Dataset yang digunakan bisa diakses pada link google drive berikut ini :\n",
    "\n",
    "https://drive.google.com/drive/folders/1sFR3uGfThCCJA6IlhomeKntaJKHBUYhO?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.56 s\n"
     ]
    }
   ],
   "source": [
    "colname = ['start','end','source_num', 'dest_num', 'access_code', 'org_dest_num', 'duration', 'dest_country', 'dest_country_status']\n",
    "data = pd.read_csv('dataset/fraud_pstn_202003.csv', sep='\\t', names=colname, parse_dates=['start', 'end'])\n",
    "fraud = pd.read_excel('dataset/fraud_pst_maret2020_label1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>source_num</th>\n",
       "      <th>dest_num</th>\n",
       "      <th>access_code</th>\n",
       "      <th>org_dest_num</th>\n",
       "      <th>duration</th>\n",
       "      <th>dest_country</th>\n",
       "      <th>dest_country_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-04 11:18:48</td>\n",
       "      <td>2020-03-04 11:20:40</td>\n",
       "      <td>315470709</td>\n",
       "      <td>61298799842</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>10176129</td>\n",
       "      <td>100.0</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>WHITELIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-04 10:07:10</td>\n",
       "      <td>2020-03-04 10:31:58</td>\n",
       "      <td>2150862540</td>\n",
       "      <td>02129974855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21299748</td>\n",
       "      <td>1487.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-04 11:23:04</td>\n",
       "      <td>2020-03-04 11:28:34</td>\n",
       "      <td>254669100</td>\n",
       "      <td>81662238903</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>10178166</td>\n",
       "      <td>319.0</td>\n",
       "      <td>JAPAN</td>\n",
       "      <td>WHITELIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-04 10:33:15</td>\n",
       "      <td>2020-03-04 10:33:19</td>\n",
       "      <td>2130069819</td>\n",
       "      <td>41794943375</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7417949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "      <td>BLACKLIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-04 10:38:14</td>\n",
       "      <td>2020-03-04 10:39:23</td>\n",
       "      <td>215265506</td>\n",
       "      <td>886227990858</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>10178862</td>\n",
       "      <td>67.0</td>\n",
       "      <td>TAIWAN</td>\n",
       "      <td>WHITELIST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                start                 end  source_num      dest_num  \\\n",
       "0 2020-03-04 11:18:48 2020-03-04 11:20:40   315470709   61298799842   \n",
       "1 2020-03-04 10:07:10 2020-03-04 10:31:58  2150862540   02129974855   \n",
       "2 2020-03-04 11:23:04 2020-03-04 11:28:34   254669100   81662238903   \n",
       "3 2020-03-04 10:33:15 2020-03-04 10:33:19  2130069819   41794943375   \n",
       "4 2020-03-04 10:38:14 2020-03-04 10:39:23   215265506  886227990858   \n",
       "\n",
       "   access_code  org_dest_num  duration dest_country dest_country_status  \n",
       "0       1017.0      10176129     100.0    AUSTRALIA           WHITELIST  \n",
       "1          NaN      21299748    1487.0          NaN                 NaN  \n",
       "2       1017.0      10178166     319.0        JAPAN           WHITELIST  \n",
       "3          7.0       7417949       0.0  SWITZERLAND           BLACKLIST  \n",
       "4       1017.0      10178862      67.0       TAIWAN           WHITELIST  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 53.5 ms\n"
     ]
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAST_UPDATE</th>\n",
       "      <th>CALL_DATE</th>\n",
       "      <th>source_num</th>\n",
       "      <th>dest_num</th>\n",
       "      <th>TOTAL_CALL</th>\n",
       "      <th>TOTAL_DURATION</th>\n",
       "      <th>DESTINATION</th>\n",
       "      <th>LAST_TRUNKIN</th>\n",
       "      <th>LAST_TRUNKOUT</th>\n",
       "      <th>CDRSOURCE</th>\n",
       "      <th>TRUNKIN_OWNER</th>\n",
       "      <th>TRUNKOUT_OWNER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-MAR-20 16:38:05</td>\n",
       "      <td>01-MAR-20 00:00:00</td>\n",
       "      <td>2129185200</td>\n",
       "      <td>88233011407</td>\n",
       "      <td>12</td>\n",
       "      <td>5478</td>\n",
       "      <td>SATELITE THURAYA</td>\n",
       "      <td>BDJK1G</td>\n",
       "      <td>GCTHKS</td>\n",
       "      <td>GB_JKT</td>\n",
       "      <td>TELKOM</td>\n",
       "      <td>TELIN HK SILVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-MAR-20 16:38:05</td>\n",
       "      <td>01-MAR-20 00:00:00</td>\n",
       "      <td>2129185200</td>\n",
       "      <td>88233011410</td>\n",
       "      <td>10</td>\n",
       "      <td>3716</td>\n",
       "      <td>SATELITE THURAYA</td>\n",
       "      <td>BDJK1G</td>\n",
       "      <td>GCTHKS</td>\n",
       "      <td>GB_JKT</td>\n",
       "      <td>TELKOM</td>\n",
       "      <td>TELIN HK SILVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-MAR-20 16:38:05</td>\n",
       "      <td>01-MAR-20 00:00:00</td>\n",
       "      <td>2129185200</td>\n",
       "      <td>88236900059</td>\n",
       "      <td>7</td>\n",
       "      <td>2789</td>\n",
       "      <td>SATELITE THURAYA</td>\n",
       "      <td>BDJK1G</td>\n",
       "      <td>GCTHKS</td>\n",
       "      <td>GB_JKT</td>\n",
       "      <td>TELKOM</td>\n",
       "      <td>TELIN HK SILVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-MAR-20 16:38:05</td>\n",
       "      <td>01-MAR-20 00:00:00</td>\n",
       "      <td>2129185200</td>\n",
       "      <td>88236900070</td>\n",
       "      <td>8</td>\n",
       "      <td>3709</td>\n",
       "      <td>SATELITE THURAYA</td>\n",
       "      <td>BDJK1G</td>\n",
       "      <td>GCTHKS</td>\n",
       "      <td>GB_JKT</td>\n",
       "      <td>TELKOM</td>\n",
       "      <td>TELIN HK SILVER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-MAR-20 17:39:54</td>\n",
       "      <td>01-MAR-20 00:00:00</td>\n",
       "      <td>2129185200</td>\n",
       "      <td>8823494016</td>\n",
       "      <td>8</td>\n",
       "      <td>6863</td>\n",
       "      <td>SATELITE THURAYA</td>\n",
       "      <td>BDJK1G</td>\n",
       "      <td>GCTHKS</td>\n",
       "      <td>GB_JKT</td>\n",
       "      <td>TELKOM</td>\n",
       "      <td>TELIN HK SILVER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          LAST_UPDATE           CALL_DATE  source_num     dest_num  \\\n",
       "0  01-MAR-20 16:38:05  01-MAR-20 00:00:00  2129185200  88233011407   \n",
       "1  01-MAR-20 16:38:05  01-MAR-20 00:00:00  2129185200  88233011410   \n",
       "2  01-MAR-20 16:38:05  01-MAR-20 00:00:00  2129185200  88236900059   \n",
       "3  01-MAR-20 16:38:05  01-MAR-20 00:00:00  2129185200  88236900070   \n",
       "4  01-MAR-20 17:39:54  01-MAR-20 00:00:00  2129185200   8823494016   \n",
       "\n",
       "   TOTAL_CALL  TOTAL_DURATION       DESTINATION LAST_TRUNKIN LAST_TRUNKOUT  \\\n",
       "0          12            5478  SATELITE THURAYA       BDJK1G        GCTHKS   \n",
       "1          10            3716  SATELITE THURAYA       BDJK1G        GCTHKS   \n",
       "2           7            2789  SATELITE THURAYA       BDJK1G        GCTHKS   \n",
       "3           8            3709  SATELITE THURAYA       BDJK1G        GCTHKS   \n",
       "4           8            6863  SATELITE THURAYA       BDJK1G        GCTHKS   \n",
       "\n",
       "  CDRSOURCE TRUNKIN_OWNER   TRUNKOUT_OWNER  \n",
       "0    GB_JKT        TELKOM  TELIN HK SILVER  \n",
       "1    GB_JKT        TELKOM  TELIN HK SILVER  \n",
       "2    GB_JKT        TELKOM  TELIN HK SILVER  \n",
       "3    GB_JKT        TELKOM  TELIN HK SILVER  \n",
       "4    GB_JKT        TELKOM  TELIN HK SILVER  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.9 ms\n"
     ]
    }
   ],
   "source": [
    "fraud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:49:41.541538Z",
     "start_time": "2020-07-22T07:49:41.486675Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391948, 9)\n",
      "(149, 12)\n",
      "time: 1.95 ms\n"
     ]
    }
   ],
   "source": [
    "print(data.shape) \n",
    "print(fraud.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand Missing Values\n",
    "\n",
    "Hal yang pertama adalah membersihkan data dari data-data yang tidak perlu ataupun NaN data (missing value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:49:45.131483Z",
     "start_time": "2020-07-22T07:49:45.058678Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start                     0\n",
       "end                       0\n",
       "source_num                0\n",
       "dest_num                  1\n",
       "access_code            2150\n",
       "org_dest_num              0\n",
       "duration                  0\n",
       "dest_country           7581\n",
       "dest_country_status    7581\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 69.4 ms\n"
     ]
    }
   ],
   "source": [
    "# Copy data ke dataframe ke nama dataframe baru\n",
    "data_clean = data.copy()\n",
    "data_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect missing `dest_num`\n",
    "Melakukan pemeriksaan pada missing value pada kolom `dest_num`, untuk digolongkan sebagai inputation error. Cari data lain dengan `source_num` yang sama dengan oberservasi missing value pada kolom `dest_num` tersebut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>source_num</th>\n",
       "      <th>dest_num</th>\n",
       "      <th>access_code</th>\n",
       "      <th>org_dest_num</th>\n",
       "      <th>duration</th>\n",
       "      <th>dest_country</th>\n",
       "      <th>dest_country_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233123</th>\n",
       "      <td>2020-03-16 21:05:36</td>\n",
       "      <td>2020-03-16 21:22:56</td>\n",
       "      <td>761943117</td>\n",
       "      <td>18778277870</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>10171877</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>WHITELIST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286070</th>\n",
       "      <td>2020-03-16 21:05:05</td>\n",
       "      <td>2020-03-16 21:05:10</td>\n",
       "      <td>761943117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     start                 end  source_num     dest_num  \\\n",
       "233123 2020-03-16 21:05:36 2020-03-16 21:22:56   761943117  18778277870   \n",
       "286070 2020-03-16 21:05:05 2020-03-16 21:05:10   761943117          NaN   \n",
       "\n",
       "        access_code  org_dest_num  duration dest_country dest_country_status  \n",
       "233123       1017.0      10171877    1031.0          USA           WHITELIST  \n",
       "286070          7.0             7       0.0          NaN                 NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47.5 ms\n"
     ]
    }
   ],
   "source": [
    "cond1 = data_clean['dest_num'].isna()\n",
    "cond1\n",
    "source_num_missing_access_code = data_clean[cond1]['source_num'].unique()\n",
    "data_clean[data_clean['source_num'].isin(source_num_missing_access_code)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari hasil yang didapat, dapat diasumsikan bahwa missing value pada kolom `dest_num` adalah kesalahan data dan dapat dihapus. Tapi terlebih dahulu di cek keterkaitannya dengan kolom lainnya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect missing `access_code`\n",
    "Melakukan pemeriksaan terhadap kolom `dest_num` yang memiliki msising value terhadap `access_code`, apakah juga berupa inputation error atau memang tidak memiliki nilai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 85.4 ms\n"
     ]
    }
   ],
   "source": [
    "cond2 = data_clean['access_code'].isna()\n",
    "dest_num_missing_country = data_clean[cond2]['dest_num'].unique()\n",
    "(data_clean[data_clean['dest_num'].isin(dest_num_missing_country)].index == data_clean[cond2].index).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari hasil yang diberikan di atas, nilai `access_code` yang missing terjadi pada beberapa nomor `dest_num`, sehingga asumsi bahwa nilai tersebut dikategorikan sebagai inputation error dapat kita abaikan, dan dapat diekslkusifkan (diremove). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:49:53.936425Z",
     "start_time": "2020-07-22T07:49:53.850500Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 57.4 ms\n"
     ]
    }
   ],
   "source": [
    "# Remove missing access_code (berdasarkan hasil di atas)\n",
    "data_clean.dropna(subset=['access_code'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect missing `dest_country`\n",
    "Periksa apakah missing `dest_country` berimplikasi pada missing `deset_country_status`. Hasil dibawah menyebutkan bahwa semua missing `dest_country`, juga missing `dest_country_status`. Lalu putuskan apakah akan menghapus data dengan missing value tersebut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 48.7 ms\n"
     ]
    }
   ],
   "source": [
    "cond3 = data_clean['dest_country'].isna()\n",
    "cond4 = data_clean['dest_country_status'].isna()\n",
    "(cond3 == cond4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.5 ms\n"
     ]
    }
   ],
   "source": [
    "source_num_missing_country = data_clean[cond3 & cond4]['source_num'].unique()\n",
    "dest_num_missing_country = data_clean[cond3 & cond4]['dest_num'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2143, 2252, 5431)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.02 ms\n"
     ]
    }
   ],
   "source": [
    "len(dest_num_missing_country), len(source_num_missing_country), len(data_clean[cond3 & cond4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>source_num</th>\n",
       "      <th>dest_num</th>\n",
       "      <th>access_code</th>\n",
       "      <th>org_dest_num</th>\n",
       "      <th>duration</th>\n",
       "      <th>dest_country</th>\n",
       "      <th>dest_country_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2020-03-02 13:01:02</td>\n",
       "      <td>2020-03-02 13:01:29</td>\n",
       "      <td>2131186485</td>\n",
       "      <td>00886986407114</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>10170088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2020-03-02 18:49:59</td>\n",
       "      <td>2020-03-02 18:49:59</td>\n",
       "      <td>274441100</td>\n",
       "      <td>839855808</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7839855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>2020-03-03 11:55:13</td>\n",
       "      <td>2020-03-03 11:55:50</td>\n",
       "      <td>2150842889</td>\n",
       "      <td>00886986411353</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>10170088</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>2020-03-05 16:56:18</td>\n",
       "      <td>2020-03-05 16:56:44</td>\n",
       "      <td>2131186117</td>\n",
       "      <td>00886973029541</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>10170088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>2020-03-01 08:24:37</td>\n",
       "      <td>2020-03-01 08:24:37</td>\n",
       "      <td>361736838</td>\n",
       "      <td>894140236</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7894140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  start                 end  source_num        dest_num  \\\n",
       "188 2020-03-02 13:01:02 2020-03-02 13:01:29  2131186485  00886986407114   \n",
       "210 2020-03-02 18:49:59 2020-03-02 18:49:59   274441100       839855808   \n",
       "218 2020-03-03 11:55:13 2020-03-03 11:55:50  2150842889  00886986411353   \n",
       "253 2020-03-05 16:56:18 2020-03-05 16:56:44  2131186117  00886973029541   \n",
       "306 2020-03-01 08:24:37 2020-03-01 08:24:37   361736838       894140236   \n",
       "\n",
       "     access_code  org_dest_num  duration dest_country dest_country_status  \n",
       "188       1017.0      10170088       0.0          NaN                 NaN  \n",
       "210          7.0       7839855       0.0          NaN                 NaN  \n",
       "218       1017.0      10170088      27.0          NaN                 NaN  \n",
       "253       1017.0      10170088       0.0          NaN                 NaN  \n",
       "306          7.0       7894140       0.0          NaN                 NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 52.2 ms\n"
     ]
    }
   ],
   "source": [
    "data_clean[data_clean['dest_num'].isin(dest_num_missing_country)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari hasil yang diberikan di atas, nilai `dest_country` yang missing terjadi pada beberapa nomor `dest_num`, sehingga asumsi bahwa nilai tersebut dikategorikan sebagai inputation error dapat kita abaikan, dan dapat dieksklusifkan (diremove). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:50:00.725824Z",
     "start_time": "2020-07-22T07:50:00.623103Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 56.4 ms\n"
     ]
    }
   ],
   "source": [
    "# delete all missing value `dest_country`\n",
    "data_clean.dropna(subset=['dest_country'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start                  0\n",
      "end                    0\n",
      "source_num             0\n",
      "dest_num               0\n",
      "access_code            0\n",
      "org_dest_num           0\n",
      "duration               0\n",
      "dest_country           0\n",
      "dest_country_status    0\n",
      "dtype: int64\n",
      "time: 84.3 ms\n"
     ]
    }
   ],
   "source": [
    "print(data_clean.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simpan data clean ke dalam file untuk mempermudah proses di selanjutnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.32 s\n"
     ]
    }
   ],
   "source": [
    "data_clean.to_csv('dataset/data_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation & Data Wrangling\n",
    "\n",
    "Tahap ini bertujuan untuk membuat data siap diolah dan dikonsumsi oleh model machine learning. Beberapa faktor yang mungkin dapat dipertimbangkan untuk di ekstrak dari data adalah sebagai berikut : \n",
    "\n",
    "- Pengelompokkan data berdasarkan nomor telepon asal dan tanggal\n",
    "- durasi overlap (jika ada)\n",
    "- interval antar panggilan telepon untuk nomor telepon asal yang sama\n",
    "- kardinalitas tetangga nomor pemanggil\n",
    "- kardinalitas tetangga nomor dipanggil\n",
    "- durasi panggilan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk kasus klasifikasi dan deteksi anomali, data harus dapat direpresentasikan sebagai state of data (1 baris sebagai 1 data). Dalam kasus ini, satu data adalah satu nomor yang menelpon ke nomor tujuan beserta informasi lainnya yang harus kita agregasikan. Tapi akan disiapkan juga data ready dengan key tidak hanya nomor telepon asal (`source_num`), sebagai pilihan data ready.\n",
    "\n",
    "Untuk itu perlu ditambahkan kolom `day` dan `week` untuk menyimpan data tanggal dari masing-masing transaksi yang nantinya bisa digunakan sebagai pengelompokkan (grouping) dan key index data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.72 s\n"
     ]
    }
   ],
   "source": [
    "data_clean = pd.read_csv('dataset/data_clean.csv', parse_dates=['start', 'end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>source_num</th>\n",
       "      <th>dest_num</th>\n",
       "      <th>access_code</th>\n",
       "      <th>...</th>\n",
       "      <th>duration</th>\n",
       "      <th>dest_country</th>\n",
       "      <th>dest_country_status</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-04 11:18:48</td>\n",
       "      <td>2020-03-04 11:20:40</td>\n",
       "      <td>315470709</td>\n",
       "      <td>61298799842</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>WHITELIST</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-04 11:23:04</td>\n",
       "      <td>2020-03-04 11:28:34</td>\n",
       "      <td>254669100</td>\n",
       "      <td>81662238903</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>...</td>\n",
       "      <td>319.0</td>\n",
       "      <td>JAPAN</td>\n",
       "      <td>WHITELIST</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-04 10:33:15</td>\n",
       "      <td>2020-03-04 10:33:19</td>\n",
       "      <td>2130069819</td>\n",
       "      <td>41794943375</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "      <td>BLACKLIST</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-04 10:38:14</td>\n",
       "      <td>2020-03-04 10:39:23</td>\n",
       "      <td>215265506</td>\n",
       "      <td>886227990858</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>TAIWAN</td>\n",
       "      <td>WHITELIST</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-04 10:40:39</td>\n",
       "      <td>2020-03-04 10:41:05</td>\n",
       "      <td>778424823</td>\n",
       "      <td>60377257257</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MALAYSIA</td>\n",
       "      <td>WHITELIST</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                start                 end  source_num      dest_num  \\\n",
       "0 2020-03-04 11:18:48 2020-03-04 11:20:40   315470709   61298799842   \n",
       "1 2020-03-04 11:23:04 2020-03-04 11:28:34   254669100   81662238903   \n",
       "2 2020-03-04 10:33:15 2020-03-04 10:33:19  2130069819   41794943375   \n",
       "3 2020-03-04 10:38:14 2020-03-04 10:39:23   215265506  886227990858   \n",
       "4 2020-03-04 10:40:39 2020-03-04 10:41:05   778424823   60377257257   \n",
       "\n",
       "   access_code  ...  duration  dest_country dest_country_status        day  \\\n",
       "0       1017.0  ...     100.0     AUSTRALIA           WHITELIST 2020-03-04   \n",
       "1       1017.0  ...     319.0         JAPAN           WHITELIST 2020-03-04   \n",
       "2          7.0  ...       0.0   SWITZERLAND           BLACKLIST 2020-03-04   \n",
       "3       1017.0  ...      67.0        TAIWAN           WHITELIST 2020-03-04   \n",
       "4          7.0  ...       4.0      MALAYSIA           WHITELIST 2020-03-04   \n",
       "\n",
       "  week  \n",
       "0   10  \n",
       "1   10  \n",
       "2   10  \n",
       "3   10  \n",
       "4   10  \n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 415 ms\n"
     ]
    }
   ],
   "source": [
    "data_clean['day'] = data_clean['start'].dt.date\n",
    "data_clean['day'] = pd.to_datetime(data_clean.day)\n",
    "data_clean['week'] = data_clean['start'].dt.week\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspeksi source\n",
    "Melakukan wrangling pada level `source_num` secara individual "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task :** Untuk setiap `source_num`, dapatkan : \n",
    "- rata-rata interval waktu antar panggilan keluar. \n",
    "- jumlah durasi panggilan \n",
    "- jumlah wilayah tujuan (`org_des_num`)\n",
    "\n",
    "Hint : Gunakan `.shift()` method untuk menghitung selisih waktu panggilan diakhiri denngan panggilan dimulai berikutnya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspeksi Source Neighbor\n",
    "Melakukan wrangling pada nomor-nomor yang mirip dengan `source_num`. \n",
    "\n",
    "**Task** : Dapatkan: \n",
    "- kardinalitas tetangga (jumlah nomor unik, inklusif)\n",
    "- kardinalitas nomor yang dipanggil (jumlah `dest_num` unik, inklusif)\n",
    "- total durasi panggilan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Aggregation \n",
    "menggabungkan antara : \n",
    "- feature `source_num` (total durasi, jumlah nomor unik yang dipanggil, jumlah wilayah yang dituju, rata-rata interval antar panggilan)\n",
    "- feature tetangga `source_num` (ukuran tetangga, jumlah nomor unik yang dipanggil, jumlah durasi panggilan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task:** Buatlah sebuah fungsi untuk melakukan wrangling data menjadi data yang siap kita jadikan sebagai input kedalam machine learning. <br>\n",
    "Input : Data Clean <br>\n",
    "Output : Ready-to-feed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample data siap pakai ada pada file `data_ready_sample.csv` dengan bentuk kurang lebih sebagai berikut (index=`source_num`): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|     source_num |   duration |   dest_num |   org_dest_num |   source_num_nunique |   dest_num_nunique |   total_duration |   avg_interval |\n",
    "|---------------:|-----------:|-----------:|---------------:|---------------------:|-------------------:|-----------------:|---------------:|\n",
    "|          21147 |        104 |         18 |             11 |                    2 |                 26 |              104 |          30306 |\n",
    "|          24147 |        954 |        116 |             29 |                    1 |                116 |              954 |          21601 |\n",
    "|         299999 |        236 |        348 |             18 |                    1 |                348 |              236 |           6911 |\n",
    "|         757845 |       1311 |          7 |              7 |                    1 |                  7 |             1311 |          45757 |\n",
    "|        2114000 |       3235 |        156 |             54 |                    7 |                177 |             3467 |          16845 |\n",
    "|        ...     |       ...  |        ... |            ... |                  ... |                ... |              ... |            ... |\n",
    "| 21806831903213 |       1087 |          2 |              2 |                    1 |                  2 |             1087 |           9922 |\n",
    "| 62895401351782 |         21 |          2 |              2 |                   23 |                 39 |              191 |           5951 |\n",
    "| 62895401351788 |         76 |          2 |              2 |                   23 |                 39 |              191 |          85835 |\n",
    "| 62895401351813 |          4 |          2 |              2 |                   23 |                 39 |              191 |          55327 |\n",
    "| 62895401351833 |         12 |          2 |              2 |                   23 |                 39 |              191 |          74845 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definisi fungsi\n",
    "\n",
    "Disiapkan fungsi untuk menghitung kardinalitas tetangga berdasarkan key index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:00:50.240179Z",
     "start_time": "2020-07-22T07:00:50.205227Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 998 µs\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk mendapatkan tetangga nomor pemanggil\n",
    "def find_neighbor(source_num, neighbor, threshold=100):\n",
    "    return neighbor[abs(neighbor - source_num) <= threshold].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:00:52.347806Z",
     "start_time": "2020-07-22T07:00:52.311755Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.99 ms\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk mendapatkan tetangga nomor pemanggil berdasarkan harian data\n",
    "def find_neighbor_day(source_num, day, neighbor_num, neighbor_day, threshold = 100) :\n",
    "    cond1 = abs(neighbor_num - source_num) <= threshold\n",
    "    cond2 = neighbor_day == day\n",
    "    return neighbor_num[cond1 & cond2].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:00:54.649525Z",
     "start_time": "2020-07-22T07:00:54.610527Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 996 µs\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk mendapatkan tetangga nomor pemanggil berdasarkan harian data dan nomor tujuan yang sama dipanggil oleh source_num\n",
    "def find_neighbor_day_dest(source_num, day, dest_num, neighbor_num, neighbor_day, neighbor_dest_num, threshold = 100) :\n",
    "    cond1 = abs(neighbor_num - source_num) <= threshold\n",
    "    cond2 = neighbor_day == day\n",
    "    cond3 = neighbor_dest_num == dest_num\n",
    "    return neighbor_num[cond1 & cond2].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menggunakan key `source_num`\n",
    "Dilakukan data wrangling pada  `source_num` sebagai index grouping per individual nomor telepon asal (`source_num`). Kemudian dilakukan agregasi untuk setiap `source_num` sebagai berikut :\n",
    "- Jumlah durasi panggilan telepon (`total_duration` : sum)\n",
    "- Jumlah panggilan telepon (`total_call` : sum)\n",
    "- Jumlah nomor tujuan unik yang ditelepon oleh nomor asal (`dest_num` : nunique)\n",
    "- Jumlah kode akses yang unik (`access_code` : nunique)\n",
    "- Jumlah wilayah tujuan yang unik (`org_dest_num` : nunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_call</th>\n",
       "      <th>total_duration</th>\n",
       "      <th>dest_num</th>\n",
       "      <th>access_code</th>\n",
       "      <th>org_dest_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21123</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21147</th>\n",
       "      <td>18</td>\n",
       "      <td>104.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24147</th>\n",
       "      <td>118</td>\n",
       "      <td>954.0</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62078</th>\n",
       "      <td>1</td>\n",
       "      <td>4062.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62147</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            total_call  total_duration  dest_num  access_code  org_dest_num\n",
       "source_num                                                                 \n",
       "21123                8             0.0         8            1             3\n",
       "21147               18           104.0        18            1            11\n",
       "24147              118           954.0       116            1            29\n",
       "62078                1          4062.0         1            1             1\n",
       "62147                1             4.0         1            1             1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 836 ms\n"
     ]
    }
   ],
   "source": [
    "data_ready_1 = data_clean.groupby(['source_num']).agg({\n",
    "    'source_num' : 'count',\n",
    "    'duration' : 'sum',\n",
    "    'dest_num' : 'nunique',\n",
    "    'access_code' : 'nunique',\n",
    "    'org_dest_num' : 'nunique'\n",
    "})\n",
    "data_ready_1.rename(columns={'source_num' : 'total_call',\n",
    "'duration' : 'total_duration'}, \n",
    "inplace=True)\n",
    "data_ready_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya dilakukan data wrangling terhadap column `source_num` yang unik, untuk bisa mendapatkan : \n",
    "- Jumlah kardinalitas nomor asal (`source_num`) yang mirip atau berdekatan secara unik.\n",
    "- Jumlah kardinalitas nomor tujuan yang (`dest_num`) yang mirip atau berdekatan secara unik ditelepon oleh tetangganya.\n",
    "- Rata-rata dari interval waktu antar panggilan keluar dari masing-masing nomor telepon (`source_num`).\n",
    "\n",
    "Kemudian gabungkan dengan data ready sebelumnya, dan simpan ke dalam file untuk pemrosesan lebih lanjut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 44227/44227 [08:04<00:00, 91.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8min 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "intervals = []\n",
    "neighbor_sources = []\n",
    "neighbor_destinations = []\n",
    "neighbor_durations = []\n",
    "for num in tqdm(data_ready_1.iloc[:].index) :\n",
    "#     print(num)\n",
    "    df = data_clean[data_clean.source_num == num]\n",
    "    interval = (df['start'].shift(-1) - df['end']).mean().seconds\n",
    "    intervals.append(interval)\n",
    "    neighbor_source = find_neighbor(num, data_clean.source_num, 50)\n",
    "    neighbor_sources.append(len(neighbor_source))\n",
    "    neighbor = data_clean[(data_clean.source_num.isin(neighbor_source))]\n",
    "    neighbor_destinations.append(neighbor.dest_num.nunique())\n",
    "    neighbor_durations.append(neighbor.duration.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 41.1 ms\n"
     ]
    }
   ],
   "source": [
    "data_ready_1['source_num_neighbor_unique'] = neighbor_sources\n",
    "data_ready_1['dest_num_neighbor_unique'] = neighbor_destinations\n",
    "data_ready_1['avg_interval'] = intervals\n",
    "data_ready_1['duration_neighbor'] = neighbor_durations\n",
    "data_ready_1['avg_interval'] = data_ready_1['avg_interval'].fillna(0)\n",
    "# data_ready_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 188 ms\n"
     ]
    }
   ],
   "source": [
    "data_ready_1.to_csv('dataset/fraud_data_ready.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menggunakan key `source_num` dan `day`\n",
    "Dilakukan data wrangling pada  `source_num` dan `day` sebagai index grouping agar data bisa dilihat harian (`day`) per individual nomor telepon asal (`source_num`). Kemudian dilakukan agregasi untuk setiap `source_num` dan `day` sebagai berikut :\n",
    "- Jumlah durasi panggilan telepon (`total_duration` : sum)\n",
    "- Jumlah panggilan telepon (`total_call` : sum)\n",
    "- Jumlah nomor tujuan unik yang ditelepon oleh nomor asal (`dest_num` : nunique)\n",
    "- Jumlah kode akses yang unik (`access_code` : nunique)\n",
    "- Jumlah wilayah tujuan yang unik (`org_dest_num` : nunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total_call</th>\n",
       "      <th>total_duration</th>\n",
       "      <th>dest_num</th>\n",
       "      <th>access_code</th>\n",
       "      <th>org_dest_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_num</th>\n",
       "      <th>day</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">21123</th>\n",
       "      <th>2020-03-12</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-18</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-21</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">21147</th>\n",
       "      <th>2020-03-01</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-02</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       total_call  total_duration  dest_num  access_code  \\\n",
       "source_num day                                                             \n",
       "21123      2020-03-12           4             0.0         4            1   \n",
       "           2020-03-18           3             0.0         3            1   \n",
       "           2020-03-21           1             0.0         1            1   \n",
       "21147      2020-03-01           1             0.0         1            1   \n",
       "           2020-03-02           4             0.0         4            1   \n",
       "\n",
       "                       org_dest_num  \n",
       "source_num day                       \n",
       "21123      2020-03-12             2  \n",
       "           2020-03-18             1  \n",
       "           2020-03-21             1  \n",
       "21147      2020-03-01             1  \n",
       "           2020-03-02             1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 430 ms\n"
     ]
    }
   ],
   "source": [
    "data_ready_2 = data_clean.groupby(['source_num', 'day']).agg({\n",
    "    'source_num' : 'count',\n",
    "    'duration' : 'sum',\n",
    "    'dest_num' : 'nunique',\n",
    "    'access_code' : 'nunique',\n",
    "    'org_dest_num' : 'nunique'\n",
    "})\n",
    "data_ready_2.rename(columns={'source_num' : 'total_call',\n",
    "'duration' : 'total_duration'}, \n",
    "inplace=True)\n",
    "data_ready_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya dilakukan data wrangling terhadap column `source_num` yang unik perhari (`day`), untuk bisa mendapatkan : \n",
    "- Jumlah kardinalitas nomor asal (`source_num`) yang mirip atau berdekatan secara unik dalam sehari.\n",
    "- Jumlah kardinalitas nomor tujuan yang (`dest_num`) yang mirip atau berdekatan secara unik ditelepon oleh tetangga nya dalam sehari.\n",
    "- Rata-rata dari interval waktu antar panggilan keluar dari masing-masing nomor telepon (`source_num`) dalam sehari.\n",
    "\n",
    "Kemudian gabungkan dengan data ready sebelumnya, dan simpan ke dalam file untuk pemrosesan lebih lanjut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 130495/130495 [29:46<00:00, 73.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29min 46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "intervals = []\n",
    "neighbor_sources = []\n",
    "neighbor_destinations = []\n",
    "neighbor_durations = []\n",
    "for num in tqdm(data_ready_2.iloc[:].index) :\n",
    "#     print(num)\n",
    "    df = data_clean[(data_clean.source_num == num[0]) & (data_clean.day == num[1])]\n",
    "    interval = (df['start'].shift(-1) - df['end']).mean().seconds\n",
    "    intervals.append(interval)\n",
    "    neighbor_source = find_neighbor_day(num[0], num[1], data_clean.source_num, data_clean.day, 50)\n",
    "    neighbor_sources.append(len(neighbor_source))\n",
    "    neighbor = data_clean[(data_clean.source_num.isin(neighbor_source)) & (data_clean.day == num[1])]\n",
    "    neighbor_destinations.append(neighbor.dest_num.nunique())\n",
    "    neighbor_durations.append(neighbor.duration.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 88.8 ms\n"
     ]
    }
   ],
   "source": [
    "data_ready_2['source_num_neighbor_unique'] = neighbor_sources\n",
    "data_ready_2['dest_num_neighbor_unique'] = neighbor_destinations\n",
    "data_ready_2['avg_interval'] = intervals\n",
    "data_ready_2['duration_neighbor'] = neighbor_durations\n",
    "data_ready_2['avg_interval'] = data_ready_2['avg_interval'].fillna(0)\n",
    "# data_ready_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "data_ready_2.to_csv('dataset/fraud_data_ready_day.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menggunakan key `source_num`, `day`, dan `dest_num`\n",
    "Dilakukan data wrangling pada  `source_num`, `day`, dan `dest_num` sebagai index grouping agar data bisa dilihat harian (`day`) per individual nomor telepon asal (`source_num`) dengan masing-masing nomor tujuan (`dest_num`). Kemudian dilakukan agregasi untuk setiap `source_num`, `day` dan `dest_num` sebagai berikut :\n",
    "- Jumlah durasi panggilan telepon (`total_duration` : sum)\n",
    "- Jumlah panggilan telepon (`total_call` : sum)\n",
    "- Jumlah nomor tujuan unik yang ditelepon oleh nomor asal (`dest_num` : nunique)\n",
    "- Jumlah kode akses yang unik (`access_code` : nunique)\n",
    "- Jumlah wilayah tujuan yang unik (`org_dest_num` : nunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:02:28.117491Z",
     "start_time": "2020-07-22T07:02:27.444057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total_call</th>\n",
       "      <th>total_duration</th>\n",
       "      <th>access_code</th>\n",
       "      <th>org_dest_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_num</th>\n",
       "      <th>day</th>\n",
       "      <th>dest_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">21123</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">2020-03-12</th>\n",
       "      <th>8613443552056</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8613443552545</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8613444552833</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8615644093456</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-18</th>\n",
       "      <th>6593342553</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     total_call  total_duration  access_code  \\\n",
       "source_num day        dest_num                                                 \n",
       "21123      2020-03-12 8613443552056           1             0.0            1   \n",
       "                      8613443552545           1             0.0            1   \n",
       "                      8613444552833           1             0.0            1   \n",
       "                      8615644093456           1             0.0            1   \n",
       "           2020-03-18 6593342553              1             0.0            1   \n",
       "\n",
       "                                     org_dest_num  \n",
       "source_num day        dest_num                     \n",
       "21123      2020-03-12 8613443552056             1  \n",
       "                      8613443552545             1  \n",
       "                      8613444552833             1  \n",
       "                      8615644093456             1  \n",
       "           2020-03-18 6593342553                1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 593 ms\n"
     ]
    }
   ],
   "source": [
    "data_ready_3 = data_clean.groupby(['source_num', 'day', 'dest_num']).agg({\n",
    "    'source_num' : 'count',\n",
    "    'duration' : 'sum',\n",
    "    'access_code' : 'nunique',\n",
    "    'org_dest_num' : 'nunique'\n",
    "})\n",
    "data_ready_3.rename(columns={'source_num' : 'total_call',\n",
    "'duration' : 'total_duration'}, \n",
    "inplace=True)\n",
    "data_ready_3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya dilakukan data wrangling terhadap column `source_num` yang unik perhari (`day`) untuk masing-masing nomor tujuan (`dest_num`), untuk bisa mendapatkan : \n",
    "- Jumlah kardinalitas nomor asal (`source_num`) yang mirip atau berdekatan secara unik dalam sehari.\n",
    "- Jumlah kardinalitas nomor tujuan yang (`dest_num`) yang mirip atau berdekatan secara unik ditelepon oleh tetangga nya dalam sehari.\n",
    "- Rata-rata dari interval waktu antar panggilan keluar dari masing-masing nomor telepon (`source_num`) dalam sehari.\n",
    "- Rata-rata dari interval waktu antar panggilan keluar dari masing-masing nomor telepon (`source_num`) dalam sehari dengan nomor tujuan yang sama.\n",
    "- Total panggilan untuk masing-masing nomor asal (`source_num`) dengan kategori include dan exclude data durasi (`duration`) yang 0 dalam sehari.\n",
    "- Total durasi untuk masing-masing nomor asal (`source_num`) dengan kategori include dan exclude data durasi (`duration`) yang 0 dalam sehari.\n",
    "- Total panggilan untuk masing-masing nomor tujuan (`dest_num`) dengan kategori include dan exclude data durasi (`duration`) yang 0 dalam sehari.\n",
    "- Rasio blacklist (`dest_country_status`) untuk masing-masing nomor asal (`source_num`) dengan kategori include dan exclude data durasi (`duration`) yang 0 dalam sehari.\n",
    "\n",
    "Kemudian gabungkan dengan data ready sebelumnya, dan simpan ke dalam file untuk pemrosesan lebih lanjut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:16:57.432634Z",
     "start_time": "2020-07-22T07:02:36.127685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 998 µs\n"
     ]
    }
   ],
   "source": [
    "intervals = []\n",
    "total_duration_source_nums = []\n",
    "total_duration_source_nums_exc = []\n",
    "total_call_source_nums = []\n",
    "total_call_source_nums_exc = []\n",
    "total_call_dest_nums = []\n",
    "total_call_dest_nums_exc = []\n",
    "intervals_all_dest_num = []\n",
    "ratio_blacklist = []\n",
    "ratio_blacklist_exc = []\n",
    "neighbor_sources = []\n",
    "neighbor_destinations = []\n",
    "neighbor_durations = []\n",
    "# for num, row in tqdm(data_ready_2.iterrows()):\n",
    "for num in tqdm(data_ready_3.iloc[:].index) :\n",
    "    # print(num)\n",
    "    df = data_clean[(data_clean.source_num == num[0]) & (data_clean.day == num[1]) & (data_clean.dest_num == num[2])]\n",
    "    interval = (df['start'].shift(-1) - df['end']).mean().seconds\n",
    "    intervals.append(interval)\n",
    "    df = data_clean[(data_clean.source_num == num[0]) & (data_clean.day == num[1])]\n",
    "    interval = (df['start'].shift(-1) - df['end']).mean().seconds\n",
    "    intervals_all_dest_num.append(interval)\n",
    "    all_call_source_num = data_clean[(data_clean.source_num == num[0]) & (data_clean.day == num[1])]\n",
    "    all_call_source_num_exc = data_clean[(data_clean.source_num == num[0]) & (data_clean.day == num[1]) & (data_clean.duration > 0)]\n",
    "    total_duration_source_nums.append(all_call_source_num['duration'].sum())\n",
    "    total_duration_source_nums_exc.append(all_call_source_num_exc['duration'].sum())\n",
    "    total_call_source_nums.append(len(all_call_source_num))\n",
    "    total_call_source_nums_exc.append(len(all_call_source_num_exc))\n",
    "    \n",
    "    all_call_dest_num = data_clean[(data_clean.dest_num == num[2]) & (data_clean.day == num[1])]\n",
    "    all_call_dest_num_exc = data_clean[(data_clean.dest_num == num[2]) & (data_clean.day == num[1]) & (data_clean.duration > 0)]\n",
    "    total_call_dest_nums.append(len(all_call_dest_num))\n",
    "    total_call_dest_nums_exc.append(len(all_call_dest_num_exc))\n",
    "    \n",
    "    # neighbor\n",
    "    neighbor_source = find_neighbor_day_dest(num[0], num[1], num[2], data_clean.source_num, data_clean.day, data_clean.dest_num, 50)\n",
    "    neighbor_sources.append(len(neighbor_source))\n",
    "    neighbor = data_clean[(data_clean.source_num.isin(neighbor_source)) & (data_clean.day == num[1]) & (data_clean.dest_num == num[2])]\n",
    "    neighbor_destinations.append(neighbor.dest_num.nunique())\n",
    "    neighbor_durations.append(neighbor.duration.sum())\n",
    "    # blacklist ratio\n",
    "    l_bl_inc = len(all_call_source_num[all_call_source_num['dest_country_status'] == 'BLACKLIST'])\n",
    "    if l_bl_inc == 0:\n",
    "        ratio_blacklist.append(0)\n",
    "    else:\n",
    "        ratio_blacklist.append(l_bl_inc/len(all_call_source_num) * 100)\n",
    "    l_bl_exc = len(all_call_source_num_exc[all_call_source_num_exc['dest_country_status'] == 'BLACKLIST'])\n",
    "    if l_bl_exc == 0:\n",
    "        ratio_blacklist_exc.append(0)\n",
    "    else:\n",
    "        ratio_blacklist_exc.append(l_bl_exc/len(all_call_source_num_exc) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready_3['avg_interval_dest_num'] = intervals\n",
    "data_ready_3['total_duration_source_num'] = total_duration_source_nums\n",
    "data_ready_3['total_duration_source_num_exc'] = total_duration_source_nums_exc\n",
    "data_ready_3['total_call_source_num'] = total_call_source_nums\n",
    "data_ready_3['total_call_source_num_exc'] = total_call_source_nums_exc\n",
    "data_ready_3['total_call_dest_num'] = total_call_dest_nums\n",
    "data_ready_3['total_call_dest_num_exc'] = total_call_dest_nums_exc\n",
    "data_ready_3['avg_interval_all_dest_num'] = intervals_all_dest_num\n",
    "data_ready_3['avg_interval_dest_num'] = data_ready_3['avg_interval_dest_num'].fillna(0)\n",
    "data_ready_3['avg_interval_all_dest_num'] = data_ready_3['avg_interval_all_dest_num'].fillna(0)\n",
    "data_ready_3['ratio_blacklist'] = ratio_blacklist_inc\n",
    "data_ready_3['ratio_blacklist_exc'] = ratio_blacklist_exc\n",
    "data_ready_3['nunique_source_num_neighbor'] = neighbor_sources\n",
    "data_ready_3['nunique_dest_num_neighbor'] = neighbor_destinations\n",
    "data_ready_3['total_duration_source_num_neighbor'] = neighbor_durations\n",
    "# data_ready_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready_3.to_csv('dataset/fraud_data_ready_day_dest_num.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Selanjutnya mulai melakukan tahap modeling dengan menggunakan **Anomaly Detection** dari `sklearn`, langkah-langkahnya sebagai berikut : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data Ready\n",
    "\n",
    "Load kembali file data ready yang ingin dimodelkan, kemudian buang data yang memiliki `total_duration` nya 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:54:53.757035Z",
     "start_time": "2020-07-22T07:54:52.890938Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.38 s\n"
     ]
    }
   ],
   "source": [
    "# Jika menggunakan Data Ready 1\n",
    "data_ready_1 = pd.read_csv('dataset/fraud_data_ready.csv', index_col=[0], skipinitialspace=True)\n",
    "\n",
    "# Jika menggunakan Data Ready 2\n",
    "data_ready_2 = pd.read_csv('dataset/fraud_data_ready_day.csv', index_col=[0,1], skipinitialspace=True)\n",
    "\n",
    "# Jika menggunakan Data Ready 3\n",
    "data_ready_3 = pd.read_csv('dataset/fraud_data_ready_day_dest_num_2.csv', index_col=[0,1,2], skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:54:56.404465Z",
     "start_time": "2020-07-22T07:54:56.210846Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 412 ms\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Jika menggunakan Data Ready 1\n",
    "data_scale_1 = scaler.fit_transform(data_ready_1)\n",
    "\n",
    "# Jika menggunakan Data Ready 2\n",
    "data_scale_2 = scaler.fit_transform(data_ready_2)\n",
    "\n",
    "# Jika menggunakan Data Ready 3\n",
    "data_scale_3 = scaler.fit_transform(data_ready_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:54:59.619886Z",
     "start_time": "2020-07-22T07:54:59.064804Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "# Jika menggunakan Data Ready 1\n",
    "dfready_scale_1 = data_ready_1.copy()\n",
    "dfready_scale_1.iloc[:,:] = data_scale_1\n",
    "\n",
    "# Jika menggunakan Data Ready 2\n",
    "dfready_scale_2 = data_ready_2.copy()\n",
    "dfready_scale_2.iloc[:,:] = data_scale_2\n",
    "\n",
    "# Jika menggunakan Data Ready 3\n",
    "dfready_scale_3 = data_ready_3.copy()\n",
    "dfready_scale_3.iloc[:,:] = data_scale_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:31:48.226462Z",
     "start_time": "2020-07-22T07:31:48.182348Z"
    }
   },
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "Menggunakan elbow method seperti di bawah ini untuk menentukan number of component yang digunakan nantinya pada saat scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.12 ms\n"
     ]
    }
   ],
   "source": [
    "rcParams['figure.figsize'] = 30, 5\n",
    "anomaly_algorithms = [('Data Ready 1', dfready_scale_1), # model one class svm disimpan dengan nama `ocsvm` \n",
    "                      ('Data Ready 2',dfready_scale_2), \n",
    "                      ('Data Ready 3',dfready_scale_3)]\n",
    "plot_num = 1\n",
    "xx, yy = np.meshgrid(np.linspace(-10, 100, 300),np.linspace(-20, 40, 200))\n",
    "for name, algorithm in anomaly_algorithms:\n",
    "    t0 = time.time()\n",
    "    pca = PCA(random_state=1).fit(algorithm)\n",
    "    t1 = time.time()\n",
    "    plt.subplot(1, len(anomaly_algorithms), plot_num)\n",
    "    plt.title(name, size=18)\n",
    "\n",
    "    colors = np.array(['#377eb8', '#ff7f00'])\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('explained variance')\n",
    "\n",
    "    plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n",
    "             transform=plt.gca().transAxes, size=15,\n",
    "             horizontalalignment='right')\n",
    "    plot_num+=1\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig('assets/plt_elbow_method.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](assets/plt_elbow_method.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari hasil plot elbow method di atas telah didapatkan number of components yang bisa digunakan, dalam kasus ini digunakan pc=8. Tapi untuk visualisasi nanti akan dilakukan setelah data prediksi didapatkan dengan pc=2 karna ingin didapat data 2 dimensi untuk bisa di-visualisasikan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-22T08:08:32.543Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "# pc_1 = 8, pc_2 = 8, pc_3 = 8\n",
    "\n",
    "pc = 8\n",
    "pca_scale = PCA(pc, random_state=1)\n",
    "dfready_scale_pca_1 = pca_scale.fit_transform(dfready_scale_1)\n",
    "dfready_scale_pca_2 = pca_scale.fit_transform(dfready_scale_2)\n",
    "dfready_scale_pca_3 = pca_scale.fit_transform(dfready_scale_3)\n",
    "\n",
    "# dfready_scale_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:42:50.735933Z",
     "start_time": "2020-07-22T07:42:50.689071Z"
    }
   },
   "source": [
    "## Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-22T07:58:19.925028Z",
     "start_time": "2020-07-22T07:58:19.870175Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.99 ms\n"
     ]
    }
   ],
   "source": [
    "# Anomaly Detection\n",
    "ocsvm_1 = svm.OneClassSVM(nu=0.1)\n",
    "rocov_1 = EllipticEnvelope(random_state=1)\n",
    "isofor_1 = IsolationForest(random_state=1)\n",
    "\n",
    "ocsvm_2 = svm.OneClassSVM(nu=0.1)\n",
    "rocov_2 = EllipticEnvelope(random_state=1)\n",
    "isofor_2 = IsolationForest(random_state=1)\n",
    "\n",
    "ocsvm_3 = svm.OneClassSVM(nu=0.1)\n",
    "rocov_3 = EllipticEnvelope(random_state=1)\n",
    "isofor_3 = IsolationForest(random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "Melakukan training data dengan model yang digunakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-22T07:59:10.664Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(random_state=1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23min 39s\n"
     ]
    }
   ],
   "source": [
    "ocsvm_1.fit(dfready_scale_pca_1)\n",
    "rocov_1.fit(dfready_scale_pca_1)\n",
    "isofor_1.fit(dfready_scale_pca_1)\n",
    "\n",
    "ocsvm_2.fit(dfready_scale_pca_2)\n",
    "rocov_2.fit(dfready_scale_pca_2)\n",
    "isofor_2.fit(dfready_scale_pca_2)\n",
    "\n",
    "ocsvm_3.fit(dfready_scale_pca_3)\n",
    "rocov_3.fit(dfready_scale_pca_3)\n",
    "isofor_3.fit(dfready_scale_pca_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simpan ke dalam file untuk kebutuhan analisa lanjutan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/isofor_3.joblib']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 680 ms\n"
     ]
    }
   ],
   "source": [
    "dump(ocsvm_1, 'dataset/ocsvm_1.joblib')\n",
    "dump(rocov_1, 'dataset/rocov_1.joblib')\n",
    "dump(isofor_1, 'dataset/isofor_1.joblib')\n",
    "\n",
    "dump(ocsvm_2, 'dataset/ocsvm_2.joblib')\n",
    "dump(rocov_2, 'dataset/rocov_2.joblib')\n",
    "dump(isofor_2, 'dataset/isofor_2.joblib')\n",
    "\n",
    "dump(ocsvm_3, 'dataset/ocsvm_3.joblib')\n",
    "dump(rocov_3, 'dataset/rocov_3.joblib')\n",
    "dump(isofor_3, 'dataset/isofor_3.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Test\n",
    "\n",
    "Fungsi decision_function untuk melihat score secara real, jika nilai score anomali semakin minus maka semakin anomali."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 323 ms\n"
     ]
    }
   ],
   "source": [
    "ocsvm_1 = load('dataset/ocsvm_1.joblib')\n",
    "rocov_1 = load('dataset/rocov_1.joblib')\n",
    "isofor_1 = load('dataset/isofor_1.joblib')\n",
    "\n",
    "ocsvm_2 = load('dataset/ocsvm_2.joblib')\n",
    "rocov_2 = load('dataset/rocov_2.joblib')\n",
    "isofor_2 = load('dataset/isofor_2.joblib')\n",
    "\n",
    "ocsvm_3 = load('dataset/ocsvm_3.joblib')\n",
    "rocov_3 = load('dataset/rocov_3.joblib')\n",
    "isofor_3 = load('dataset/isofor_3.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-22T07:47:07.793Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "score_rocov_1 = rocov_1.decision_function(dfready_scale_pca_1)\n",
    "score_ocsvm_1 = ocsvm_1.decision_function(dfready_scale_pca_1)\n",
    "score_isofor_1 = isofor_1.decision_function(dfready_scale_pca_1)\n",
    "\n",
    "score_rocov_2 = rocov_2.decision_function(dfready_scale_pca_2)\n",
    "score_ocsvm_2 = ocsvm_2.decision_function(dfready_scale_pca_2)\n",
    "score_isofor_2 = isofor_2.decision_function(dfready_scale_pca_2)\n",
    "\n",
    "score_rocov_3 = rocov_3.decision_function(dfready_scale_pca_3)\n",
    "score_ocsvm_3 = ocsvm_3.decision_function(dfready_scale_pca_3)\n",
    "score_isofor_3 = isofor_3.decision_function(dfready_scale_pca_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "# Membuat prediksi dari masing-masing model\n",
    "pred_rocov_1 = rocov_1.predict(dfready_scale_pca_1)\n",
    "pred_ocsvm_1 = ocsvm_1.predict(dfready_scale_pca_1)\n",
    "pred_isofor_1 = isofor_1.predict(dfready_scale_pca_1)\n",
    "\n",
    "pred_rocov_2 = rocov_2.predict(dfready_scale_pca_2)\n",
    "pred_ocsvm_2 = ocsvm_2.predict(dfready_scale_pca_2)\n",
    "pred_isofor_2 = isofor_2.predict(dfready_scale_pca_2)\n",
    "\n",
    "pred_rocov_3 = rocov_3.predict(dfready_scale_pca_3)\n",
    "pred_ocsvm_3 = ocsvm_3.predict(dfready_scale_pca_3)\n",
    "pred_isofor_3 = isofor_3.predict(dfready_scale_pca_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-22T08:12:14.497Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.95 ms\n"
     ]
    }
   ],
   "source": [
    "# Simpan index dimana anomali data ditangkap\n",
    "idx_rocov_1 = np.where(pred_rocov_1 == -1)\n",
    "idx_ocsvm_1 = np.where(pred_ocsvm_1 == -1)\n",
    "idx_isofor_1 = np.where(pred_isofor_1 == -1)\n",
    "\n",
    "idx_rocov_2 = np.where(pred_rocov_2 == -1)\n",
    "idx_ocsvm_2 = np.where(pred_ocsvm_2 == -1)\n",
    "idx_isofor_2 = np.where(pred_isofor_2 == -1)\n",
    "\n",
    "idx_rocov_3 = np.where(pred_rocov_3 == -1)\n",
    "idx_ocsvm_3 = np.where(pred_ocsvm_3 == -1)\n",
    "idx_isofor_3 = np.where(pred_isofor_3 == -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-22T07:47:16.526Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    2,     7,    11, ..., 44099, 44100, 44101], dtype=int64),)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.96 ms\n"
     ]
    }
   ],
   "source": [
    "np.where(pred_rocov_1 == -1)\n",
    "np.where(pred_ocsvm_1 == -1)\n",
    "np.where(pred_isofor_1 == -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Prediksi dan dapatkan kira-kira data apa saja yang terindikasi fraudulent. Berikut adalah gambaran hasil yang diberikan (dari data ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/data_predict_svm_3.joblib']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 75.8 ms\n"
     ]
    }
   ],
   "source": [
    "data_predict_svm_1 = data_ready_1.iloc[idx_ocsvm_1[0],:]\n",
    "data_predict_svm_2 = data_ready_2.iloc[idx_ocsvm_2[0],:]\n",
    "data_predict_svm_3 = data_ready_3.iloc[idx_ocsvm_3[0],:]\n",
    "\n",
    "dump(data_predict_svm_1, 'dataset/data_predict_svm_1.joblib')\n",
    "dump(data_predict_svm_2, 'dataset/data_predict_svm_2.joblib')\n",
    "dump(data_predict_svm_3, 'dataset/data_predict_svm_3.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/data_predict_cov_3.joblib']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 52.1 ms\n"
     ]
    }
   ],
   "source": [
    "data_predict_cov_1 = data_ready_1.iloc[idx_rocov_1[0],:]\n",
    "data_predict_cov_2 = data_ready_2.iloc[idx_rocov_2[0],:]\n",
    "data_predict_cov_3 = data_ready_3.iloc[idx_rocov_3[0],:]\n",
    "\n",
    "dump(data_predict_cov_1, 'dataset/data_predict_cov_1.joblib')\n",
    "dump(data_predict_cov_2, 'dataset/data_predict_cov_2.joblib')\n",
    "dump(data_predict_cov_3, 'dataset/data_predict_cov_3.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/data_predict_isofor_3.joblib']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 46.9 ms\n"
     ]
    }
   ],
   "source": [
    "data_predict_isofor_1 = data_ready_1.iloc[idx_isofor_1[0],:]\n",
    "data_predict_isofor_2 = data_ready_2.iloc[idx_isofor_2[0],:]\n",
    "data_predict_isofor_3 = data_ready_3.iloc[idx_isofor_3[0],:]\n",
    "\n",
    "dump(data_predict_isofor_1, 'dataset/data_predict_isofor_1.joblib')\n",
    "dump(data_predict_isofor_2, 'dataset/data_predict_isofor_2.joblib')\n",
    "dump(data_predict_isofor_3, 'dataset/data_predict_isofor_3.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d Visualization \n",
    "Lalu interpretasikan (dan cocokkan) data-data yang anomali dari hasil reduksi dimensi menggunakan visualisasi plotly berikut : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.95 ms\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(dfready_scale_pca_1,columns=['pc1','pc2','pc3','pc4','pc5','pc6','pc7','pc8'],index=data_ready_1.index)\n",
    "df2 = pd.DataFrame(dfready_scale_pca_2,columns=['pc1','pc2','pc3','pc4','pc5','pc6','pc7','pc8'],index=data_ready_2.index)\n",
    "df3 = pd.DataFrame(dfready_scale_pca_3,columns=['pc1','pc2','pc3','pc4','pc5','pc6','pc7','pc8'],index=data_ready_3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.07 s\n"
     ]
    }
   ],
   "source": [
    "pc = 2\n",
    "pca_scale = PCA(pc, random_state=1)\n",
    "dfready_pca_1 = pca_scale.fit_transform(df1)\n",
    "dfready_pca_2 = pca_scale.fit_transform(df2)\n",
    "dfready_pca_3 = pca_scale.fit_transform(df3)\n",
    "\n",
    "# dfready_tsne_1 = TSNE(n_components=pc).fit_transform(df1)\n",
    "# dfready_tsne_2 = TSNE(n_components=pc).fit_transform(df2)\n",
    "# dfready_tsne_3 = TSNE(n_components=pc).fit_transform(df3)\n",
    "\n",
    "# dfready_tsne_1 = TSNE(n_components=pc).fit_transform(dfready_scale_1)\n",
    "# dfready_tsne_2 = TSNE(n_components=pc).fit_transform(dfready_scale_2)\n",
    "# dfready_tsne_3 = TSNE(n_components=pc).fit_transform(dfready_scale_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.99 ms\n"
     ]
    }
   ],
   "source": [
    "df_tsne_1 = pd.DataFrame(dfready_pca_1,columns=['pc1','pc2'],index=data_ready_1.index)\n",
    "df_tsne_2 = pd.DataFrame(dfready_pca_2,columns=['pc1','pc2'],index=data_ready_2.index)\n",
    "df_tsne_3 = pd.DataFrame(dfready_pca_3,columns=['pc1','pc2'],index=data_ready_3.index)\n",
    "\n",
    "# df_tsne_1 = pd.DataFrame(dfready_tsne_1,columns=['pc1','pc2'],index=data_ready_1.index)\n",
    "# df_tsne_2 = pd.DataFrame(dfready_tsne_2,columns=['pc1','pc2'],index=data_ready_2.index)\n",
    "# df_tsne_3 = pd.DataFrame(dfready_tsne_3,columns=['pc1','pc2'],index=data_ready_3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 473 ms\n"
     ]
    }
   ],
   "source": [
    "# Join data hasil scaling di atas dengan data_ready yang di atas.\n",
    "df_1 = df_tsne_1.join(data_ready_1)\n",
    "df_2 = df_tsne_2.join(data_ready_2)\n",
    "df_3 = df_tsne_3.join(data_ready_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "df_pca_1 = df_tsne_1.copy()\n",
    "df_pca_2 = df_tsne_2.copy()\n",
    "df_pca_3 = df_tsne_3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assets/plt_data_ready_1.html'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.6 s\n"
     ]
    }
   ],
   "source": [
    "# Menggunakan Data Ready 1\n",
    "df = df_1.copy()\n",
    "fig = px.scatter(df, x=\"pc1\", y=\"pc2\", hover_data=[df.index.get_level_values(0), \n",
    "    df.index, \n",
    "    'pc1','pc2', 'total_call', 'total_duration'])\n",
    "# fig.show()\n",
    "plotly.offline.plot(fig, filename='assets/plt_data_ready_1.html', image='png', auto_open=True, output_type='file', image_width=800, image_height=600, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menggunakan data ready 1 maka akan menghasilkan plot seperti berikut : \n",
    "\n",
    "![ ](assets/plt_data_ready_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assets/plt_data_ready_2.html'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.14 s\n"
     ]
    }
   ],
   "source": [
    "#Menggunakan Data Ready 2\n",
    "df = df_2.copy()\n",
    "fig = px.scatter(df, x=\"pc1\", y=\"pc2\", hover_data=[df.index.get_level_values(0), \n",
    "    df.index.get_level_values(1), \n",
    "    'pc1','pc2', 'total_call', 'total_duration'])\n",
    "# fig.show()\n",
    "plotly.offline.plot(fig, filename='assets/plt_data_ready_2.html', image='png', auto_open=True, output_type='file', image_width=800, image_height=600, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menggunakan data ready 2 maka akan menghasilkan plot seperti berikut : \n",
    "\n",
    "![ ](assets/plt_data_ready_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assets/plt_data_ready_3.html'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "#Menggunakan Data Ready 3\n",
    "df = df_3.copy()\n",
    "fig = px.scatter(df, x=\"pc1\", y=\"pc2\", hover_data=[df.index.get_level_values(0), \n",
    "    df.index.get_level_values(1), \n",
    "    df.index.get_level_values(2),\n",
    "    'pc1','pc2', 'total_call', 'total_duration'])\n",
    "# fig.show()\n",
    "plotly.offline.plot(fig, filename='assets/plt_data_ready_3.html', image='png', auto_open=True, output_type='file', image_width=800, image_height=600, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Menggunakan data ready 3 maka akan menghasilkan plot seperti berikut : \n",
    "\n",
    "![ ](assets/plt_data_ready_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performa masing-masing model **Anomaly Detection** seperti gambar berikut :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.02 ms\n"
     ]
    }
   ],
   "source": [
    "# Dengan menggunakan data ready 1\n",
    "rcParams['figure.figsize'] = 30, 5\n",
    "anomaly_algorithms = [('One Class SVM', ocsvm_1), # model one class svm disimpan dengan nama `ocsvm` \n",
    "                      ('Robust Covariance',rocov_1), \n",
    "                      ('Isolation Forest',isofor_1)]\n",
    "plot_num = 1\n",
    "xx, yy = np.meshgrid(np.linspace(-10, 100, 300),np.linspace(-20, 40, 200))\n",
    "for name, algorithm in anomaly_algorithms:\n",
    "    model = algorithm\n",
    "    t0 = time.time()\n",
    "    model.fit(df_pca_1)\n",
    "    t1 = time.time()\n",
    "    plt.subplot(1, len(anomaly_algorithms), plot_num)\n",
    "\n",
    "    plt.title(name, size=18)\n",
    "\n",
    "    # fit the data and tag outliers\n",
    "    y_pred = algorithm.predict(df_pca_1)\n",
    "\n",
    "    # plot the levels lines and the points\n",
    "    Z = algorithm.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='black')\n",
    "\n",
    "    colors = np.array(['#377eb8', '#ff7f00'])\n",
    "    plt.scatter(df_pca_1['pc1'], df_pca_1['pc2'], s=10, color=colors[(y_pred + 1) // 2])\n",
    "    plt.xlim(-20, 100)\n",
    "    plt.ylim(-20, 50)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n",
    "             transform=plt.gca().transAxes, size=15,\n",
    "             horizontalalignment='right')\n",
    "    plot_num+=1\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig('assets/plt_anomaly_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](assets/plt_anomaly_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.02 ms\n"
     ]
    }
   ],
   "source": [
    "# Dengan menggunakan data ready 2\n",
    "rcParams['figure.figsize'] = 30, 5\n",
    "anomaly_algorithms = [('One Class SVM', ocsvm_2), # model one class svm disimpan dengan nama `ocsvm` \n",
    "                      ('Robust Covariance',rocov_2), \n",
    "                      ('Isolation Forest',isofor_2)]\n",
    "plot_num = 1\n",
    "xx, yy = np.meshgrid(np.linspace(-10, 100, 300),np.linspace(-20, 40, 200))\n",
    "for name, algorithm in anomaly_algorithms:\n",
    "    model = algorithm\n",
    "    t0 = time.time()\n",
    "    model.fit(df_pca_2)\n",
    "    t1 = time.time()\n",
    "    plt.subplot(1, len(anomaly_algorithms), plot_num)\n",
    "\n",
    "    plt.title(name, size=18)\n",
    "\n",
    "    # fit the data and tag outliers\n",
    "    y_pred = algorithm.predict(df_pca_2)\n",
    "\n",
    "    # plot the levels lines and the points\n",
    "    Z = algorithm.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='black')\n",
    "\n",
    "    colors = np.array(['#377eb8', '#ff7f00'])\n",
    "    plt.scatter(df_pca_2['pc1'], df_pca_2['pc2'], s=10, color=colors[(y_pred + 1) // 2])\n",
    "    plt.xlim(-20, 100)\n",
    "    plt.ylim(-20, 50)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n",
    "             transform=plt.gca().transAxes, size=15,\n",
    "             horizontalalignment='right')\n",
    "    plot_num+=1\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig('assets/plt_anomaly_2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](assets/plt_anomaly_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 990 µs\n"
     ]
    }
   ],
   "source": [
    "# Dengan menggunakan data ready 3\n",
    "rcParams['figure.figsize'] = 30, 5\n",
    "anomaly_algorithms = [('One Class SVM', ocsvm_3), # model one class svm disimpan dengan nama `ocsvm` \n",
    "                      ('Robust Covariance',rocov_3), \n",
    "                      ('Isolation Forest',isofor_3)]\n",
    "plot_num = 1\n",
    "xx, yy = np.meshgrid(np.linspace(-10, 100, 300),np.linspace(-20, 40, 200))\n",
    "for name, algorithm in anomaly_algorithms:\n",
    "    model = algorithm\n",
    "    t0 = time.time()\n",
    "    model.fit(df_pca_3)\n",
    "    t1 = time.time()\n",
    "    plt.subplot(1, len(anomaly_algorithms), plot_num)\n",
    "\n",
    "    plt.title(name, size=18)\n",
    "\n",
    "    # fit the data and tag outliers\n",
    "    y_pred = algorithm.predict(df_pca_3)\n",
    "\n",
    "    # plot the levels lines and the points\n",
    "    Z = algorithm.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='black')\n",
    "\n",
    "    colors = np.array(['#377eb8', '#ff7f00'])\n",
    "    plt.scatter(df_pca_3['pc1'], df_pca_3['pc2'], s=10, color=colors[(y_pred + 1) // 2])\n",
    "    plt.xlim(-20, 100)\n",
    "    plt.ylim(-20, 50)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n",
    "             transform=plt.gca().transAxes, size=15,\n",
    "             horizontalalignment='right')\n",
    "    plot_num+=1\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig('assets/plt_anomaly_3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ ](assets/plt_anomaly_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi\n",
    "\n",
    "Bandingkan dengan dataframe **fraud** yang berupa data fraud berdasarkan rule base untuk masing-masing hasil prediksi. Cek mana yang paling cocok atau paling banyak menangkap nomor telepon fraud yang sama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.96 ms\n"
     ]
    }
   ],
   "source": [
    "fraud.set_index(['source_num'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.41 s\n"
     ]
    }
   ],
   "source": [
    "data_predict_svm_1 = load('dataset/data_predict_svm_1.joblib')\n",
    "data_predict_cov_1 = load('dataset/data_predict_cov_1.joblib')\n",
    "data_predict_isofor_1 = load('dataset/data_predict_isofor_1.joblib')\n",
    "\n",
    "data_predict_svm_2 = load('dataset/data_predict_svm_2.joblib')\n",
    "data_predict_cov_2 = load('dataset/data_predict_cov_2.joblib')\n",
    "data_predict_isofor_2 = load('dataset/data_predict_isofor_2.joblib')\n",
    "\n",
    "data_predict_svm_3 = load('dataset/data_predict_svm_3.joblib')\n",
    "data_predict_cov_3 = load('dataset/data_predict_cov_3.joblib')\n",
    "data_predict_isofor_3 = load('dataset/data_predict_isofor_3.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 11)\n",
      "(4225, 9)\n",
      "(4423, 9)\n",
      "(5390, 9)\n",
      "time: 973 µs\n"
     ]
    }
   ],
   "source": [
    "# Cek jumlah nomor telepon unik untuk masing-masing dataframe.\n",
    "print(fraud.shape)\n",
    "print(data_predict_svm_1.shape)\n",
    "print(data_predict_cov_1.shape)\n",
    "print(data_predict_isofor_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "4225\n",
      "4423\n",
      "5390\n",
      "time: 27.7 ms\n"
     ]
    }
   ],
   "source": [
    "# Cek jumlah nomor telepon unik untuk masing-masing dataframe.\n",
    "print(fraud.index.nunique())\n",
    "print(data_predict_svm_1.index.get_level_values(0).nunique())\n",
    "print(data_predict_cov_1.index.get_level_values(0).nunique())\n",
    "print(data_predict_isofor_1.index.get_level_values(0).nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "5390\n",
      "3977\n",
      "5636\n",
      "time: 3.96 ms\n"
     ]
    }
   ],
   "source": [
    "# Cek jumlah nomor telepon unik untuk masing-masing dataframe.\n",
    "print(fraud.index.nunique())\n",
    "print(data_predict_isofor_1.index.get_level_values(0).nunique())\n",
    "print(data_predict_isofor_2.index.get_level_values(0).nunique())\n",
    "print(data_predict_isofor_3.index.get_level_values(0).nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge (union) data dari masing-masing hasil model prediksi untuk menyaring data anomaly lebih banyak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15176\n",
      "15239\n",
      "9613\n",
      "time: 492 ms\n"
     ]
    }
   ],
   "source": [
    "data_merge_svm = data_predict_svm_1.merge(data_predict_svm_2, how='outer', on=['source_num'])\n",
    "data_merge_svm = data_merge_svm.merge(data_predict_svm_3, how='outer', on=['source_num'])\n",
    "print(data_merge_svm.index.nunique())\n",
    "\n",
    "data_merge_cov = data_predict_cov_1.merge(data_predict_cov_2, how='outer', on=['source_num'])\n",
    "data_merge_cov = data_merge_cov.merge(data_predict_cov_3, how='outer', on=['source_num'])\n",
    "print(data_merge_cov.index.nunique())\n",
    "\n",
    "data_merge_isofor = data_predict_isofor_1.merge(data_predict_isofor_2, how='outer', on=['source_num'])\n",
    "data_merge_isofor = data_merge_isofor.merge(data_predict_isofor_3, how='outer', on=['source_num'])\n",
    "print(data_merge_isofor.index.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lanjutkan dengan melakukan komparasi (irisan) data nomor telepon asal yang unik terhadap data fraud berdasarkan rule base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 72.9 ms\n"
     ]
    }
   ],
   "source": [
    "compare_svm = data_merge_svm.merge(fraud, how='inner', on=['source_num'])\n",
    "compare_svm.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 19.8 ms\n"
     ]
    }
   ],
   "source": [
    "compare_cov = data_merge_cov.merge(fraud, how='inner', on=['source_num'])\n",
    "compare_cov.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 39.9 ms\n"
     ]
    }
   ],
   "source": [
    "compare_isofor = data_merge_isofor.merge(fraud, how='inner', on=['source_num'])\n",
    "compare_isofor.index.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kesimpulan\n",
    "\n",
    "Dari hasil model **Anomaly Detection** di atas dapat dilihat **Isolation Forest** lebih sedikit menangkap anomali data. Dan jumlahnya tidak terpaut jauh pada saat dilakukan union data dari ke-3 data ready dibandingkan dengan menggunakan model lain yang terpaut jauh. Akan tetapi ketika menangkap kecocokan data dengan data fraud berdasarkan rule base lebih sedikit dibanding model lainnya.\n",
    "\n",
    "Untuk itu perlu dilakukan pengecekan lanjutan terhadap data prediksi ini untuk mengetahui data fraud yang sesungguhnya, karna data prediksi ini bukan menandakan fraud yang sesungguhnya.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone Env",
   "language": "python",
   "name": "caps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "toc-autonumbering": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
